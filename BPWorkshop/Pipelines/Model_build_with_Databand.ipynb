{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Build a customer churn model and monitor the process in Databand"}, {"metadata": {}, "cell_type": "markdown", "source": "*In this notebook we build a customer churn model and monitor some of the steps in Databand. We also log metadata for the training dataset and model training metrcis.*  \n\nWe structured this notebook so that it can be used both interactively and in the batch mode because data scientists often need to understand and review data before they build the model. Notice that cells up to **Step 2: build model** produce output that can be reviewed. In **Step 2** we switch to modular programming (functions) because it will allow us to execution of each function in Databand (we add the *@task* decorator from the Databand SDK). We track 2 steps - building the model and saving it to the project.  \n\nReview all cells in the notebook, make the required changes, and run all cells either step by step or the entire notebook. View results of the run in Databand.\n\nYou will need to make the following changes in the notebook (see cells for specific instructions):\n- Add project token\n- Add Cloud API key\n- Add your Cloud URL"}, {"metadata": {}, "cell_type": "code", "source": "# IMPORTANT: Insert project token before running the notebook. Generated code is needed for WML API to save the model in the project", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# DATABAND\n# Run once during notebook execution to install the Databand SDK\n!pip install databand", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# DATABAND\n# Import Databand libraries\nfrom dbnd import dbnd_tracking, task, dataset_op_logger,log_metric", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Step 1: Explore and prepare Data"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "# Libraries for data understanding and model building\n!pip install pandas_profiling\n!pip install sklearn-pandas\n# Update WML library\n!pip install -U ibm-watson-machine-learning", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nimport pandas_profiling\nimport sklearn.pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, LabelBinarizer, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, accuracy_score, roc_curve, roc_auc_score\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\nimport json\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Load and review data "}, {"metadata": {}, "cell_type": "code", "source": "url='https://raw.githubusercontent.com/elenalowery/data-samples/main/churn.csv'\n    \ncustomer_churn = pd.read_csv(url)\ncustomer_churn.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "url='https://raw.githubusercontent.com/elenalowery/data-samples/main/customer-profile.csv'\n\ncustomer = pd.read_csv(url)\ncustomer.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Merge Files"}, {"metadata": {}, "cell_type": "code", "source": "trainingData = pd.merge(customer, customer_churn, on='ID')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Rename some columns\nThis step is to remove spaces from columns names, it's an example of data preparation that you may want to do before creating a model. "}, {"metadata": {}, "cell_type": "code", "source": "trainingData.columns", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "trainingData.rename(columns={'Est Income':'EstIncome', 'Car Owner':'CarOwner' }, inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "trainingData.head()", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "trainingData.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Data understanding"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "trainingData.describe()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pandas_profiling.ProfileReport(trainingData)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# TODO: figure out a more elegant way to do this\n# Repeating this step here because it's used by more than one function\n\n\n# Define input data to the model\nX = trainingData.drop(['ID','CHURN'], axis=1)\n    \n# Define the target variable and encode with value between 0 and n_classes-1, that is from T/F to 1/0\nle = LabelEncoder()\ny = le.fit_transform(trainingData['CHURN'])\n    \nlabel_mapping=le.inverse_transform([0,1])\n    \n# split the data to training and testing set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Step 2: Build the sklearn pipeline and the Random Forest model\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Notice that we now define functions with a *@task* above it. *@task* is provided by the Databand SDK. It lets Databand know that we are starting an execution of a pipeline step.  \n\nIn notebooks functons do not execute until they are invoked. Function definitions are provided above the call to the function. When you run through the function cells, the notebook will show completion of the cell execution, but the code does not actually run. All cells below will be invoked by the last cell that calls *buildCustomerChurnModel()*"}, {"metadata": {}, "cell_type": "code", "source": "@task\ndef train_model(trainingData):\n    \n    # Define input data to the model\n    X = trainingData.drop(['ID','CHURN'], axis=1)\n    \n    # Define the target variable and encode with value between 0 and n_classes-1, that is from T/F to 1/0\n    le = LabelEncoder()\n    y = le.fit_transform(trainingData['CHURN'])\n    \n    label_mapping=le.inverse_transform([0,1])\n    \n    # split the data to training and testing set\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n    \n    # Log model training data in Databand\n    with dataset_op_logger(\"CPDaaS://MLOps_Deployment/churnTrainingData\", \"read\", with_schema=True, with_preview=True) as logger:\n        logger.set(data=trainingData)\n    \n    mapper_good = DataFrameMapper([\n    (['Gender'], LabelBinarizer()),\n    (['Status'], LabelBinarizer()),\n    (['CarOwner'], LabelBinarizer()),\n    (['Paymethod'], LabelBinarizer()),\n    (['MembershipPlan'], LabelBinarizer()),\n    (['Children'],  StandardScaler()),\n    (['EstIncome'],  StandardScaler()),\n    (['Age'],  StandardScaler()),\n    (['AvgMonthlySpend'],  StandardScaler()),\n    (['CustomerSupportCalls'],  StandardScaler())], default=False)\n    \n    # Instantiate the Classifier\n    random_forest = RandomForestClassifier(random_state=5)\n\n    # Define the steps in the pipeline to sequentially apply a list of transforms and the estimator, i.e. RandomForestClassifier\n    steps = [('mapper', mapper_good),('RandonForestClassifier', random_forest)]\n    pipeline = sklearn.pipeline.Pipeline(steps)\n\n    # train the model\n    model=pipeline.fit( X_train, y_train )\n    \n    # Display Label Mapping to assist with interpretation of the model\n    label_mapping=le.inverse_transform([0,1])\n\n    ### call pipeline.predict() on your X_test data to make a set of test predictions\n    y_prediction = pipeline.predict( X_test )\n\n    ### test your predictions using sklearn.classification_report()\n    report = sklearn.metrics.classification_report( y_test, y_prediction )\n    \n    parameters = { 'RandonForestClassifier__max_depth': [5,8,10],\n               'RandonForestClassifier__n_estimators': [150,180,200]}\n    \n    grid_obj = GridSearchCV(estimator=model, param_grid=parameters,  cv=3)\n    \n    # Fit the grid search object to the training data and find the optimal parameters using fit()\n    grid_fit = grid_obj.fit(X_train,y_train)\n    \n    # Get the estimator\n    best_clf = grid_fit.best_estimator_\n    \n    # Fit the grid search object to the training data and find the optimal parameters using fit()\n    grid_fit = grid_obj.fit(X_train,y_train)\n    \n    best_predictions = best_clf.predict(X_test)\n    \n    best_predictions_report = sklearn.metrics.classification_report( y_test, best_predictions )\n    \n    print('Results of best fitted model: \\n\\n',best_predictions_report)\n    \n    # Get accuracy and roc_auc values to save as metrics in Databand\n    accuracy = accuracy_score(y_test, best_predictions)\n    roc_score = roc_auc_score(y_test, best_predictions)\n    \n    # DATABAND\n    log_metric('customer_churn_build_accuracy', accuracy)\n    log_metric('customer_churn_build_roc', roc_score)\n    # END DATABAND\n    \n    m_step=pipeline.named_steps['mapper']\n    \n    m_step.transformed_names_\n    \n    features = m_step.transformed_names_\n    \n    # Get the features importance\n    importances = pipeline.named_steps['RandonForestClassifier'][1].feature_importances_\n    indices = np.argsort(importances)\n    \n    # DATABAND\n    # Log feature importance in Databand\n    # Convert the importances object to a pandas dataframe in order to log it, and log it in Databand\n    importances_pd = pd.DataFrame.from_dict({'feature': np.array(features)[indices], 'importances_score': importances[indices]}).sort_values(by=['importances_score'], ascending=False)\n    with dataset_op_logger(\"CPDaaS://MLOps_Deployment/FeatureImportance\", \"read\", with_schema=True, with_preview=True) as logger:\n        logger.set(data=importances_pd)\n    # END DATABAND\n    \n    plt.figure(1)\n    plt.title('Feature Importances')\n    plt.barh(range(len(indices)), importances[indices], color='b',align='center')\n    plt.yticks(range(len(indices)), (np.array(features))[indices])\n    plt.xlabel('Relative Importance')\n    \n    return pipeline\n    ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "@task\ndef save_model_in_project(pipeline):\n    \n    from ibm_watson_machine_learning import APIClient\n\n    # IMPORTANT\n    # Replace with your Cloud API key and location. Cloud API key is available in our IBM Cloud dashboard under Manage - IAM (top menu bar)\n    api_key = 'insert_api_key'\n    location = 'insert_location_url'  # For example, Dallas location is 'https://us-south.ml.cloud.ibm.com'\n\n\n    wml_credentials = {\n        \"apikey\": api_key,\n        \"url\": location\n    }\n\n    client = APIClient(wml_credentials)\n    \n    client.set.default_project(pc.projectID)\n    \n    # Provide metadata and save the model into the repository. After running this cell, the model will be displayed in the Assets view\n\n    # Model Metadata\n\n    model_name = 'customer_churn_model'\n    software_spec_uid = client.software_specifications.get_uid_by_name('runtime-22.1-py3.9')\n\n    metadata = {\n        client.repository.ModelMetaNames.NAME: model_name,\n        client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n        client.repository.ModelMetaNames.TYPE: \"scikit-learn_1.0\"\n    }\n\n    stored_model_details = client.repository.store_model(pipeline,\n                                                   meta_props=metadata,\n                                                   training_data=X_train,\n                                                   training_target=y_train)\n      ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def buildCustomerChurnModel():\n\n    # # DATABAND\n    # Start databand tracking\n    # TODO: Update databand URL and token\n    with dbnd_tracking(\n            conf={\n                \"core\": {\n                    \"databand_url\": \"insert_url\",\n                    \"databand_access_token\": \"insert_token\",\n\n                }\n            },\n            job_name = \"buildCustomerChurnModel\",\n            run_name = \"weekly\",\n            project_name = \"Customer Analytics\",\n    ):\n\n        # Call the step job - train model\n        pipeline = train_model(trainingData)\n        \n        # Save the model\n        save_model_in_project(pipeline)\n\n\n        print(\"Finished running the model building notebook\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Invoke model traning/saving functions\nbuildCustomerChurnModel()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**In this version of the notebook we will perform deployment steps in the UI.**"}, {"metadata": {}, "cell_type": "markdown", "source": "**Author:**  Elena Lowery and Catherine Cao <br/>\n**Date:**  August 31, 2022"}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}